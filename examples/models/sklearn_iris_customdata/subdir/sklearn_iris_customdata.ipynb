{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# !pip install grpcio grpcio-tools"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scikit-Learn Iris Model using customData\n",
    "\n",
    "* Wrap a scikit-learn python model for use as a prediction microservice in seldon-core\n",
    "    * Run locally on Docker to test\n",
    "    * Deploy on seldon-core running on a Kubernetes cluster"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dependencies\n",
    "\n",
    "* [s2i](https://github.com/openshift/source-to-image)\n",
    "* Seldon Core v1.0.3+ installed\n",
    "* `pip install sklearn seldon-core protobuf grpcio`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train locally"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "def main():\n",
    "    clf = LogisticRegression()\n",
    "    p = Pipeline([(\"clf\", clf)])\n",
    "    print(\"Training model...\")\n",
    "    p.fit(X, y)\n",
    "    print(\"Model trained!\")\n",
    "\n",
    "    filename_p = \"IrisClassifier.sav\"\n",
    "    print(\"Saving model in %s\" % filename_p)\n",
    "    joblib.dump(p, filename_p)\n",
    "    print(\"Model saved!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading iris data set...\")\n",
    "    iris = datasets.load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "    print(\"Dataset loaded!\")\n",
    "    main()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading iris data set...\n",
      "Dataset loaded!\n",
      "Training model...\n",
      "Model trained!\n",
      "Saving model in IrisClassifier.sav\n",
      "Model saved!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/kachau/.local/share/virtualenvs/seldon-core-zr8TvrYf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom Protobuf Specification\n",
    "\n",
    "First, we'll need to define our custom protobuf specification so that it can be leveraged."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "%%writefile iris.proto\n",
    "\n",
    "syntax = \"proto3\";\n",
    "\n",
    "package iris;\n",
    "\n",
    "message IrisPredictRequest {\n",
    "    float sepal_length = 1;\n",
    "    float sepal_width = 2;\n",
    "    float petal_length = 3;\n",
    "    float petal_width = 4;\n",
    "}\n",
    "\n",
    "message IrisPredictResponse {\n",
    "    float setosa = 1;\n",
    "    float versicolor = 2;\n",
    "    float virginica = 3;\n",
    "}"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting iris.proto\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom Protobuf Compilation\n",
    "\n",
    "We will need to compile our custom protobuf for python so that we can unpack the `customData` field passed to our `predict` method later on."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "!python -m grpc.tools.protoc --python_out=./ --proto_path=. iris.proto"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## gRPC test\n",
    "\n",
    "Wrap model using s2i"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "!s2i build  ../ seldonio/seldon-core-s2i-python38-ubi8:1.11.0 chauhankaranraj/sklearn-iris-customdata:0.1"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---> Installing application source...\n",
      "---> Installing dependencies ...\n",
      "Looking in links: /whl\n",
      "WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Collecting scikit-learn\n",
      "Downloading scikit_learn-0.24.2-cp38-cp38-manylinux2010_x86_64.whl (24.9 MB)\n",
      "Requirement already satisfied: grpcio in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.40.0)\n",
      "WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Collecting joblib>=0.11\n",
      "Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Collecting scipy>=0.19.1\n",
      "Downloading scipy-1.7.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.4 MB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 1)) (1.21.2)\n",
      "WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.8/site-packages (from grpcio->-r requirements.txt (line 2)) (1.16.0)\n",
      "Installing collected packages: joblib, scipy, threadpoolctl, scikit-learn\n",
      "Successfully installed joblib-1.0.1 scikit-learn-0.24.2 scipy-1.7.1 threadpoolctl-2.2.0\n",
      "WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "WARNING: You are using pip version 20.2; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\n",
      "Collecting pip-licenses\n",
      "Downloading pip_licenses-3.5.2-py3-none-any.whl (17 kB)\n",
      "Collecting PTable\n",
      "Downloading PTable-0.9.2.tar.gz (31 kB)\n",
      "Building wheels for collected packages: PTable\n",
      "Building wheel for PTable (setup.py): started\n",
      "Building wheel for PTable (setup.py): finished with status 'done'\n",
      "Created wheel for PTable: filename=PTable-0.9.2-py3-none-any.whl size=22907 sha256=8a39e888207039abb8d1c1ad720b90a2cbc94759fea195251be6f37988beda97\n",
      "Stored in directory: /root/.cache/pip/wheels/1b/3a/02/8d8da2bca2223dda2f827949c88b2d82dc85dccbc2bb6265e5\n",
      "Successfully built PTable\n",
      "Installing collected packages: PTable, pip-licenses\n",
      "Successfully installed PTable-0.9.2 pip-licenses-3.5.2\n",
      "WARNING: You are using pip version 20.2; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\n",
      "created path: ./licenses/license_info.csv\n",
      "created path: ./licenses/license.txt\n",
      "Build completed successfully\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Serve the model locally"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "!docker run --name \"iris_predictor\" -d --rm -p 5000:5000 chauhankaranraj/sklearn-iris-customdata:0.1"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0bd97e43d7381a5647d64547174977ef04f9f113a84d56ac2432b3aab0b47c6d\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test using custom protobuf payload"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import grpc\n",
    "from iris_pb2 import IrisPredictRequest, IrisPredictResponse\n",
    "\n",
    "from seldon_core.proto import prediction_pb2, prediction_pb2_grpc\n",
    "\n",
    "channel = grpc.insecure_channel(\"localhost:5000\")\n",
    "stub = prediction_pb2_grpc.ModelStub(channel)\n",
    "\n",
    "iris_request = IrisPredictRequest(\n",
    "    sepal_length=7.233, sepal_width=4.652, petal_length=7.39, petal_width=0.324\n",
    ")\n",
    "\n",
    "seldon_request = prediction_pb2.SeldonMessage()\n",
    "seldon_request.customData.Pack(iris_request)\n",
    "\n",
    "response = stub.Predict(seldon_request)\n",
    "\n",
    "iris_response = IrisPredictResponse()\n",
    "response.customData.Unpack(iris_response)\n",
    "\n",
    "print(iris_response)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seldon_core'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_218199/2131066014.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0miris_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIrisPredictRequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIrisPredictResponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mseldon_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprediction_pb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_pb2_grpc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mchannel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsecure_channel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"localhost:5000\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seldon_core'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Stop serving model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "!docker rm iris_predictor --force"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Error: No such container: iris_predictor\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup Seldon Core\n",
    "\n",
    "Use the [setup notebook](https://github.com/SeldonIO/seldon-core/blob/master/notebooks/seldon_core_setup.ipynb) to setup Seldon Core with an ingress - either Ambassador or Istio\n",
    "\n",
    "Then port-forward to that ingress on localhost:8003 in a separate terminal either with:\n",
    "\n",
    "* Ambassador: `kubectl port-forward $(kubectl get pods -n seldon -l app.kubernetes.io/name=ambassador -o jsonpath='{.items[0].metadata.name}') -n seldon 8003:8080`\n",
    "* Istio: `kubectl port-forward $(kubectl get pods -l istio=ingressgateway -n istio-system -o jsonpath='{.items[0].metadata.name}') -n istio-system 8003:80`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!kubectl create namespace seldon"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!kubectl config set-context $(kubectl config current-context) --namespace=seldon"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deploy your Seldon Model\n",
    "\n",
    "We first create a configuration file:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%writefile sklearn_iris_customdata_deployment.yaml\n",
    "\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: seldon-deployment-example\n",
    "spec:\n",
    "  name: sklearn-iris-deployment\n",
    "  predictors:\n",
    "  - componentSpecs:\n",
    "    - spec:\n",
    "        containers:\n",
    "        - image: groszewn/sklearn-iris-customdata:0.1\n",
    "          imagePullPolicy: IfNotPresent\n",
    "          name: sklearn-iris-classifier\n",
    "    graph:\n",
    "      children: []\n",
    "      endpoint:\n",
    "        type: GRPC\n",
    "      name: sklearn-iris-classifier\n",
    "      type: MODEL\n",
    "    name: sklearn-iris-predictor\n",
    "    replicas: 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run the model in our cluster\n",
    "\n",
    "Apply the Seldon Deployment configuration file we just created"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!kubectl create -f sklearn_iris_customdata_deployment.yaml"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check that the model has been deployed"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!kubectl rollout status deploy/$(kubectl get deploy -l seldon-deployment-id=seldon-deployment-example -o jsonpath='{.items[0].metadata.name}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test by sending prediction calls\n",
    "\n",
    "`IrisPredictRequest` sent via the `customData` field."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "iris_request = IrisPredictRequest(\n",
    "    sepal_length=7.233, sepal_width=4.652, petal_length=7.39, petal_width=0.324\n",
    ")\n",
    "\n",
    "seldon_request = prediction_pb2.SeldonMessage()\n",
    "seldon_request.customData.Pack(iris_request)\n",
    "\n",
    "channel = grpc.insecure_channel(\"localhost:8003\")\n",
    "stub = prediction_pb2_grpc.SeldonStub(channel)\n",
    "\n",
    "metadata = [(\"seldon\", \"seldon-deployment-example\"), (\"namespace\", \"seldon\")]\n",
    "\n",
    "response = stub.Predict(request=seldon_request, metadata=metadata)\n",
    "\n",
    "iris_response = IrisPredictResponse()\n",
    "response.customData.Unpack(iris_response)\n",
    "\n",
    "print(iris_response)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cleanup our deployment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!kubectl delete -f sklearn_iris_customdata_deployment.yaml"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('seldon-core-zr8TvrYf': pipenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "interpreter": {
   "hash": "fbe97a9073fea78fd868bc3d6fb810079a90b1c45b6345e9ce78c4b2797a6233"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}